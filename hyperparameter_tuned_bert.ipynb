{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeoChuanito/My-Paper-on-detecting-cyberbullying-in-X/blob/main/hyperparameter_tuned_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzd116L6JPIH",
        "outputId": "2925562b-26c9-42bc-cfed-c576ff7173c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'bert-sklearn'...\n",
            "remote: Enumerating objects: 259, done.\u001b[K\n",
            "remote: Total 259 (delta 0), reused 0 (delta 0), pack-reused 259\u001b[K\n",
            "Receiving objects: 100% (259/259), 516.15 KiB | 1.41 MiB/s, done.\n",
            "Resolving deltas: 100% (131/131), done.\n",
            "Processing /content/bert-sklearn\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from bert-sklearn==0.3.1) (2.3.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from bert-sklearn==0.3.1) (1.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-sklearn==0.3.1) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from bert-sklearn==0.3.1) (2.0.3)\n",
            "Collecting boto3 (from bert-sklearn==0.3.1)\n",
            "  Downloading boto3-1.34.121-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-sklearn==0.3.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bert-sklearn==0.3.1) (4.66.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->bert-sklearn==0.3.1) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->bert-sklearn==0.3.1) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->bert-sklearn==0.3.1) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->bert-sklearn==0.3.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->bert-sklearn==0.3.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->bert-sklearn==0.3.1) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=0.4.1->bert-sklearn==0.3.1)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=0.4.1->bert-sklearn==0.3.1)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=0.4.1->bert-sklearn==0.3.1)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=0.4.1->bert-sklearn==0.3.1)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=0.4.1->bert-sklearn==0.3.1)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=0.4.1->bert-sklearn==0.3.1)\n"
          ]
        }
      ],
      "source": [
        "# git clone -b master https://github.com/charles9n/bert-sklearn\n",
        "# cd bert-sklearn\n",
        "# !pip install .\n",
        "!git clone -b master https://github.com/charles9n/bert-sklearn\n",
        "!cd bert-sklearn; pip install .\n",
        "import os\n",
        "os.chdir(\"bert-sklearn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6skgvhk0Vxph"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import AdamW\n",
        "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from typing import Union, List\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from bert_sklearn import BertClassifier\n",
        "from bert_sklearn import BertRegressor\n",
        "from bert_sklearn import load_model\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (8,5)\n",
        "plt.rcParams['font.size'] = 14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UIdJntTV9XL"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lACpC107V7t9"
      },
      "outputs": [],
      "source": [
        "def load_data(dataFile:str) -> Union[List, List]:\n",
        "    df = pd.read_csv(dataFile)\n",
        "    texts = df['tweet_text'].tolist()\n",
        "    labels = df['cyberbullying_type'].tolist()\n",
        "    return texts, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kckVdCx5V_Vu"
      },
      "outputs": [],
      "source": [
        "dataFile = '/content/cyberbullying_tweets.csv'\n",
        "texts, labels = load_data(dataFile)\n",
        "len(texts), len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBxVVaYUWFi3"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({'text':texts, 'labels':labels})\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQKL-9JVWDrB"
      },
      "outputs": [],
      "source": [
        "labEncoder = LabelEncoder()\n",
        "labEncoder.fit(labels)\n",
        "labelsEncoded = labEncoder.transform(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBKEq7LcWHRm"
      },
      "outputs": [],
      "source": [
        "any(df.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oP6cdzkXWJWl"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "az4fNpDTWLDK"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 7))\n",
        "sb.countplot(data=df, x='labels')\n",
        "plt.title(\"Label Distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ws6wWwyuWM8m"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81jFlaV4WPXt"
      },
      "outputs": [],
      "source": [
        "df['length'] = df['text'].str.len()\n",
        "sb.boxplot(data=df, y='length')\n",
        "plt.title(\"Length of Tweets\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fnJ8jjcWUSY"
      },
      "source": [
        "## Reduce the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cemPGUB8WQ6y"
      },
      "outputs": [],
      "source": [
        "df = df[((df['length'] > 10)\t& (df['length'] < 30))]\n",
        "df.info()\n",
        "sb.boxplot(df['length'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LhHbZDZWXWL"
      },
      "outputs": [],
      "source": [
        "def word_count(x):\n",
        "    return len(x.split())\n",
        "\n",
        "df['word_count'] = df['text'].apply(word_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pCYtwJCWcfj"
      },
      "outputs": [],
      "source": [
        "sb.boxplot(data=df, y='word_count')\n",
        "plt.title(\"Word Count in Tweets\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDuMCHMIWe4e"
      },
      "source": [
        "## Preprocessing (Data building)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJt_ougcq8Jp"
      },
      "outputs": [],
      "source": [
        "df['labels'].value_counts()\n",
        "# df['text'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Awd8YEhcqAqt"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "\n",
        "# df['text'] = le.fit_transform(df['text'])\n",
        "df['labels'] = le.fit_transform(df['labels'])\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFOuQmtcL2VA"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter grid\n",
        "# param_grid = {\n",
        "#     'learning_rate': [1e-5, 2e-5, 3e-5],\n",
        "#     'batch_size': [8, 16],\n",
        "#     'num_epochs': [3, 4, 5]\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ae9zNg05WiL5"
      },
      "outputs": [],
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
        "        input_ids = encoding['input_ids'].squeeze()\n",
        "        attention_mask = encoding['attention_mask'].squeeze()\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IZp8o52XSO0"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fe9nXHU9Pt56"
      },
      "outputs": [],
      "source": [
        "bert_model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3btBwvAQcIT"
      },
      "outputs": [],
      "source": [
        "x_train = df['text']\n",
        "y_train = df['labels']\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = tts(x_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrPfRPI8Wkad"
      },
      "outputs": [],
      "source": [
        "class BERTClassifier(torch.nn.Module):\n",
        "    def __init__(self, bert_model_name, num_classes):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
        "        self.dropout = torch.nn.Dropout(0.1)\n",
        "        self.fc = torch.nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        x = self.dropout(pooled_output)\n",
        "        logits = self.fc(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoyajG_HXsJW"
      },
      "outputs": [],
      "source": [
        "def train(model, data_loader, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    for batch in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PolFhM-zXvFI"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            actuals.extend(labels.cpu().numpy())\n",
        "    accuracy = accuracy_score(actuals, predictions)\n",
        "    report = classification_report(actuals, predictions)\n",
        "    return accuracy, report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkoFknchQNGd"
      },
      "outputs": [],
      "source": [
        "class BERTClassifierWrapper(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, bert_model_name='bert-base-uncased', num_classes=20, learning_rate=1e-5, batch_size=16, num_epochs=3):\n",
        "        self.bert_model_name = bert_model_name\n",
        "        self.num_classes = num_classes\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.num_epochs = num_epochs\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def tokenize_data(self, texts):\n",
        "        if isinstance(texts, str):\n",
        "            texts = [texts]\n",
        "        encoded = self.tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "        return encoded\n",
        "\n",
        "    def build_model(self):\n",
        "        model = BertModel.from_pretrained(self.bert_model_name)\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        classifier = nn.Sequential(\n",
        "            nn.Linear(model.config.hidden_size, self.num_classes)\n",
        "        )\n",
        "\n",
        "        model.classifier = classifier\n",
        "        return model.to(self.device)\n",
        "\n",
        "    def tokenize_data(self, texts):\n",
        "        return self.tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        print(f'Fitting model with learning_rate={self.learning_rate}, batch_size={self.batch_size}, num_epochs={self.num_epochs}')\n",
        "\n",
        "        self.model.train()\n",
        "        optimizer = optim.Adam(self.model.classifier.parameters(), lr=self.learning_rate)\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        dataset = TextDataset(X, y, self.tokenizer)\n",
        "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        for epoch in range(self.num_epochs):\n",
        "            epoch_loss = 0\n",
        "            for batch in dataloader:\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                input_ids = batch['input_ids'].to(self.device)\n",
        "                attention_mask = batch['attention_mask'].to(self.device)\n",
        "                labels = batch['labels'].to(self.device)\n",
        "\n",
        "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.last_hidden_state[:, 0, :]  # Get [CLS] token output\n",
        "                logits = self.model.classifier(logits)\n",
        "\n",
        "                loss = loss_fn(logits, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            print(f'Epoch {epoch+1}/{self.num_epochs}, Loss: {epoch_loss/len(dataloader)}')\n",
        "\n",
        "    def predict(self, X):\n",
        "        self.model.eval()\n",
        "        dataset = TextDataset(X, None, self.tokenizer, is_test=True)\n",
        "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "        all_preds = []\n",
        "        with torch.no_grad():\n",
        "            for batch in dataloader:\n",
        "                input_ids = batch['input_ids'].to(self.device)\n",
        "                attention_mask = batch['attention_mask'].to(self.device)\n",
        "\n",
        "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.last_hidden_state[:, 0, :]  # Get [CLS] token output\n",
        "                logits = self.model.classifier(logits)\n",
        "\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "        return np.array(all_preds)\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, is_test=False):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.is_test = is_test\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoded = self.tokenizer(self.texts[idx], padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n",
        "        item = {key: val.squeeze(0) for key, val in encoded.items()}\n",
        "\n",
        "        if not self.is_test:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "\n",
        "        return item"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qMKci1ojM8c"
      },
      "source": [
        "## Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9GUodGy_2Cl"
      },
      "outputs": [],
      "source": [
        "dataset = pd.DataFrame(df)\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XULFUjNCBtU4"
      },
      "outputs": [],
      "source": [
        "dataset = pd.DataFrame(df)\n",
        "Xtrain = dataset['text'].tolist()\n",
        "Ytrain = dataset['labels'].tolist()\n",
        "\n",
        "# print(dataset)\n",
        "# print(Xtrain)\n",
        "# print(Ytrain)\n",
        "\n",
        "# Xtrain = df['text']\n",
        "# Ytrain = df['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "068768d327414850b92041bfed269e63"
          ]
        },
        "id": "QJTp-BGvXvvm",
        "collapsed": true,
        "outputId": "cff2e726-442b-4f00-ad26-4e7b07d5307a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building sklearn text classifier...\n",
            "Building sklearn text classifier...\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "Building sklearn text classifier...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 4110638.09B/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading bert-base-uncased model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 440473133/440473133 [00:17<00:00, 25418336.03B/s]\n",
            "100%|██████████| 433/433 [00:00<00:00, 1000073.59B/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to linear classifier/regressor\n",
            "Loading Pytorch checkpoint\n",
            "\n",
            "train data size: 856, validation data size: 0\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "068768d327414850b92041bfed269e63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training  :   0%|          | 0/54 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-3f4d1d054444>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Perform grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/bert-sklearn/bert_sklearn/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, load_at_start)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;31m# finetune model!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinetune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/bert-sklearn/bert_sklearn/finetune.py\u001b[0m in \u001b[0;36mfinetune\u001b[0;34m(model, X1, X2, y, config)\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# step the optimizer every grad_accum_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Grid search parameters\n",
        "param_grid = {\n",
        "    'max_seq_length': [128],\n",
        "    'learning_rate': [5e-5],\n",
        "    'train_batch_size' : [16],\n",
        "    'epochs': [3]\n",
        "}\n",
        "model = BertClassifier(validation_fraction=0, max_seq_length=64)\n",
        "# Create GridSearchCV instance\n",
        "grid_search = GridSearchCV(estimator=model,\n",
        "                           param_grid=param_grid,\n",
        "                           scoring='accuracy',\n",
        "                           cv=2,\n",
        "                           verbose=1,\n",
        "                           n_jobs=1,\n",
        "                           error_score='raise')\n",
        "\n",
        "# Perform grid search\n",
        "grid_search.fit(Xtrain, Ytrain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO7qfJMhYBOS"
      },
      "source": [
        "## getting the best params after tuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vGqC9scri2xO"
      },
      "outputs": [],
      "source": [
        "# Print best parameters and results\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best accuracy found: \", grid_search.best_score_)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}